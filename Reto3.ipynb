{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importacion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingesta de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo = ('Data/reto_agua.csv')\n",
    "df = pd.read_csv(archivo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisis Exploratorio y Transformacion de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.funder.value_counts().sum()            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.wpt_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({'none': np.nan, None: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({'None': np.nan, None: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min = ['funder', 'installer', 'wpt_name', 'basin', 'region', 'public_meeting', 'recorded_by',\n",
    "'scheme_management', 'permit', 'extraction_type', 'management_group', 'payment_type', 'water_quality',\n",
    "'quality_group', 'quantity_group', 'source_class', 'waterpoint_type_group', 'status_group']\n",
    "\n",
    "def minusculas(df, columnas):\n",
    "    for i in columnas:\n",
    "        df[i] = df[i].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "    return df\n",
    "\n",
    "print(\"Valores NaN antes de aplicar la función:\")\n",
    "print(df.isna().sum())\n",
    "df = minusculas(df, min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analisis de columnas en forma individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_column(df, column_name):\n",
    "  \n",
    "    col_data = df[column_name]\n",
    "    result = {}\n",
    "    result['column_name'] = column_name\n",
    "    result['dtype'] = col_data.dtype\n",
    "    result['missing_values'] = col_data.isnull().sum()\n",
    "    result['missing_percentage'] = (col_data.isnull().sum() / len(col_data)) * 100\n",
    "    \n",
    "    if pd.api.types.is_numeric_dtype(col_data):\n",
    "        result['description'] = col_data.describe()\n",
    "    elif pd.api.types.is_bool_dtype(col_data):\n",
    "        result['value_counts'] = col_data.value_counts()\n",
    "    elif pd.api.types.is_string_dtype(col_data):\n",
    "        result['description'] = col_data.describe()\n",
    "        result['value_counts'] = col_data.value_counts()\n",
    "    else:\n",
    "        result['description'] = col_data.describe(include='all')\n",
    "        result['value_counts'] = col_data.value_counts()\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def print_analysis(analysis):\n",
    "    \n",
    "    print(f\"\\nAnálisis para la columna: {analysis['column_name']}\")\n",
    "    print(f\"Tipo de dato: {analysis['dtype']}\")\n",
    "    print(f\"Valores nulos: {analysis['missing_values']} ({analysis['missing_percentage']:.2f}%)\")\n",
    "    \n",
    "    if 'description' in analysis:\n",
    "        print(\"\\nEstadísticas descriptivas:\")\n",
    "        print(analysis['description'])\n",
    "    \n",
    "    if 'outliers' in analysis:\n",
    "        print(f\"\\nValores atípicos (outliers): {analysis['outliers']}\")\n",
    "        if analysis['outliers'] > 0:\n",
    "            print(analysis['outliers_data'])\n",
    "    \n",
    "    if 'value_counts' in analysis:\n",
    "        print(\"\\nFrecuencia de valores:\")\n",
    "        print(analysis['value_counts'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mauro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_analyze = ['population','public_meeting','recorded_by', 'scheme_management', 'permit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bucle para analizar cada columna en la lista y almacenar resultados\n",
    "analyses = []\n",
    "for column in columns_to_analyze:\n",
    "    analysis = analyze_column(df, column)\n",
    "    analyses.append(analysis)\n",
    "\n",
    "for analysis in analyses:\n",
    "    print_analysis(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Columna 'population'\n",
    "# Se Mantiene la columna sin cambios.\n",
    "# Es importante entender por qué hay tantos valores de población cero.\n",
    "# Podría ser útil investigar si estos pozos están en áreas completamente deshabitadas \n",
    "# o si se trata de áreas rurales muy dispersas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Columna 'public_meeting' Faltan 5.77%\n",
    "# Reemplazar los valores faltantes con True pq True es top frecuencia con 47292 y categorizar\n",
    "df['public_meeting'] = df['public_meeting'].fillna(True)\n",
    "df['public_meeting'] = df['public_meeting'].astype(int)\n",
    "df['public_meeting'] = df['public_meeting'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Columna 'recorded_by' 1 registro cargo todos los datoa es irrelevante drop\n",
    "# Eliminar la columna 'recorded_by'\n",
    "df = df.drop(columns='recorded_by')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Columna 'scheme_management' faltan 6.64% de los datos \n",
    "#Imputar valores faltantes con la categoría más frecuente (VWC) 34459 y luego categorizar\n",
    "df['scheme_management'] = df['scheme_management'].fillna('VWC')\n",
    "categories = df['scheme_management'].unique()\n",
    "category_map = {category: idx for idx, category in enumerate(categories)}\n",
    "df['scheme_management'] = df['scheme_management'].apply(lambda x: category_map[x])\n",
    "df['scheme_management'] = df['scheme_management'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Columna 'permit' \n",
    "# Reemplazar los valores faltantes (5%) con True pq True es top frecuencia con 47292\n",
    "df['permit'] = df['permit'].fillna(True) \n",
    "df['permit'] = df['permit'].astype(int) # Convertir a binario: True -> 1, False -> 0\n",
    "df['permit'] = df['permit'].astype('int8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ariel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_analyze = ['quality_group', 'quantity_group', 'source_class', 'waterpoint_type_group','status_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyses = []\n",
    "for column in columns_to_analyze:\n",
    "    analysis = analyze_column(df, column)\n",
    "    analyses.append(analysis)\n",
    "\n",
    "for analysis in analyses:\n",
    "    print_analysis(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Columna 'quality_group'\n",
    "# Renombrar la columna 'quality_group' a 'water_quality_2'y luego categorizar\n",
    "df.rename(columns={'quality_group': 'water_quality_2'}, inplace=True)\n",
    "categories = df['water_quality_2'].unique()\n",
    "category_map = {category: idx for idx, category in enumerate(categories)}\n",
    "df['water_quality_2'] = df['water_quality_2'].apply(lambda x: category_map[x])\n",
    "df['water_quality_2'] = df['water_quality_2'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Columna 'quantity_group' se categoriza\n",
    "categories = df['quantity_group'].unique()\n",
    "category_map = {category: idx for idx, category in enumerate(categories)}\n",
    "df['quantity_group'] = df['quantity_group'].apply(lambda x: category_map[x])\n",
    "df['quantity_group'] = df['quantity_group'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Columna 'source_class'\n",
    "categories = df['source_class'].unique()\n",
    "category_map = {category: idx for idx, category in enumerate(categories)}\n",
    "df['source_class'] = df['source_class'].apply(lambda x: category_map[x])\n",
    "df['source_class'] = df['source_class'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Columna 'waterpoint_type_group'\n",
    "categories = df['waterpoint_type_group'].unique()\n",
    "category_map = {category: idx for idx, category in enumerate(categories)}\n",
    "df['waterpoint_type_group'] = df['waterpoint_type_group'].apply(lambda x: category_map[x])\n",
    "df['waterpoint_type_group'] = df['waterpoint_type_group'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Columna 'status_group'\n",
    "categories = df['status_group'].unique()\n",
    "category_map = {category: idx for idx, category in enumerate(categories)}\n",
    "df['status_group'] = df['status_group'].apply(lambda x: category_map[x])\n",
    "df['status_group'] = df['status_group'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10colum = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ariel: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_analyze = ['amount_tsh', 'funder', 'gps_height', 'installer', 'longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyses = []\n",
    "for column in columns_to_analyze:\n",
    "    analysis = analyze_column(df, column)\n",
    "    analyses.append(analysis)\n",
    "\n",
    "for analysis in analyses:\n",
    "    print_analysis(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount_tsh'] = df['amount_tsh'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['funder'])\n",
    "\n",
    "funder_map = {\n",
    "    'government of tanzania': 1,\n",
    "    'danida': 2,\n",
    "    'hesawa': 3,\n",
    "    'rwssp': 4,\n",
    "    'world bank': 5\n",
    "}\n",
    "df['funder'] = df['funder'].apply(lambda x: funder_map.get(x, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gps_height no la toco, esta ok. reviso -90 y no es un outliers\n",
    "df.gps_height.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.installer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#installer tiene Valores nulos: 3215 (5.84%)\n",
    "df = df.dropna(subset=['installer'])\n",
    "\n",
    "funder_map = {\n",
    "    'dwe': 1,\n",
    "    'government': 2,\n",
    "    'hesawa': 3,\n",
    "    'rwe': 4,\n",
    "    'commu': 5\n",
    "}\n",
    "df['installer'] = df['installer'].apply(lambda x: funder_map.get(x, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los registros anómalos de coordenadas en total\n",
    "anomalous_records = (df['longitude'] == 0) & (np.abs(df['latitude']) < 1e-6)\n",
    "df = df[~anomalous_records]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_analyze = ['latitude','wpt_name', 'num_private', 'basin', 'region']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyses = []\n",
    "for column in columns_to_analyze:\n",
    "    analysis = analyze_column(df, column)\n",
    "    analyses.append(analysis)\n",
    "\n",
    "for analysis in analyses:\n",
    "    print_analysis(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.wpt_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wpt_name\n",
    "df = df.dropna(subset=['wpt_name'])\n",
    "\n",
    "funder_map = {\n",
    "    'shuleni': 1,\n",
    "    'zahanati': 2,\n",
    "    'msikitini': 3,\n",
    "    'kanisani': 4,\n",
    "    'ofisini': 5\n",
    "}\n",
    "df['wpt_name'] = df['wpt_name'].apply(lambda x: funder_map.get(x, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.wpt_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='num_private')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#region categorizar\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['region'] = label_encoder.fit_transform(df['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASIN categorizar\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['basin'] = label_encoder.fit_transform(df['basin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gabriel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modificación columnas object a int64\n",
    "\n",
    "df['payment_type'] = df['payment_type'].apply(lambda x: 0 if x == 'unknown' \n",
    "                                                else (1 if x == 'other' else (2 if x == 'on failure' \n",
    "                                                    else (3 if x == 'never pay' else(4 if x == 'annually' else(5 if x == 'monthly' else 6))))))\n",
    "df.payment_type.unique()\n",
    "\n",
    "df['management_group'] = df['management_group'].apply(lambda x: 0 if x == 'unknown' \n",
    "                                                else (1 if x == 'other' else (2 if x == 'parastatal' \n",
    "                                                    else (3 if x == 'commercial' else 4))))\n",
    "df.management_group.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='water_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.construction_year.value_counts()\n",
    "df.construction_year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la mediana del año de construcción para pozos funcionales y no funcionales\n",
    "median_functional = df[df['status_group'] == 1]['construction_year'].replace(0, pd.NA).median()\n",
    "median_non_functional = df[df['status_group'] == 0]['construction_year'].replace(0, pd.NA).median()\n",
    "\n",
    "def fill_missing_year(row):\n",
    "    if row['construction_year'] == 0:\n",
    "        if row['status_group'] == 1:\n",
    "            return median_functional\n",
    "        else:\n",
    "            return median_non_functional\n",
    "    return row['construction_year']\n",
    "\n",
    "df['construction_year'] = df.apply(fill_missing_year, axis=1)\n",
    "df['construction_year'] = df['construction_year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraction_type categorizar\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "df['extraction_type'] = label_encoder.fit_transform(df['extraction_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creacion de *CSV* con la Data preparada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Data/Reto_agua_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "file_path = 'Reto_agua_final.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Calcular la matriz de correlación\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Configurar el tamaño de la figura\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Crear el mapa de calor\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "\n",
    "# Configurar los títulos\n",
    "plt.title('Matriz de Correlación', size=15)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Ejercicio 2 \n",
    "\n",
    "Ahora, vamos a entrenar el modelo: \n",
    "\n",
    "• Dividid los datos en variable independiente y target \n",
    "• Dividid el modelo en un conjunto de datos para el test (20%) y otro para el train (80%) \n",
    "y random_state=42 \n",
    "• Entrenad varios modelos con los datos de train, validadlo con el test y seleccionad \n",
    "el que mejor resultado obtiene. \n",
    "Una vez hecho esto, responded a las siguientes preguntas: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "• ¿Qué score da el de entrenamiento y con el test? \n",
    "\n",
    "• ¿Creéis que puede tener sobreajuste (overfitting) o infraajuste (underfitting)?\n",
    "\n",
    "Respuesta posible luego de evaluar los modelo:\n",
    "\n",
    "Logistic Regression\n",
    "Observación: Las precisiones en el conjunto de entrenamiento y prueba son iguales (0.75).\n",
    "Conclusión: Este modelo no muestra signos de sobreajuste ni infraajuste, pero su desempeño es relativamente bajo, lo que sugiere que podría no ser el mejor modelo para estos datos.\n",
    "\n",
    "K-Nearest Neighbors (KNN)\n",
    "Observación: La precisión en el conjunto de entrenamiento (0.87) es mayor que en el conjunto de prueba (0.80).\n",
    "Conclusión: Hay una ligera diferencia, lo que indica un posible sobreajuste, aunque no es extremo. El modelo generaliza relativamente bien.\n",
    "\n",
    "Random Forest\n",
    "Observación: La precisión en el conjunto de entrenamiento es perfecta (1.00) mientras que en el conjunto de prueba es alta (0.91).\n",
    "Conclusión: Este modelo muestra claros signos de sobreajuste, ya que tiene una precisión perfecta en el conjunto de entrenamiento. Sin embargo, aún generaliza bien en el conjunto de prueba.\n",
    "\n",
    "XGBoost\n",
    "Observación: La precisión en el conjunto de entrenamiento (0.93) es ligeramente mayor que en el conjunto de prueba (0.90).\n",
    "Conclusión: Hay un pequeño margen de diferencia, lo que sugiere un buen equilibrio entre ajuste y generalización. Este modelo no muestra signos significativos de sobreajuste ni infraajuste.\n",
    "\n",
    "Resumen\n",
    "\n",
    "Logistic Regression: No muestra signos de sobreajuste ni infraajuste, pero tiene un desempeño moderado.\n",
    "\n",
    "K-Nearest Neighbors: Ligero sobreajuste, pero generaliza bien.\n",
    "\n",
    "Random Forest: Muestra signos claros de sobreajuste.\n",
    "\n",
    "XGBoost: Buen equilibrio entre ajuste y generalización, siendo el mejor modelo en términos de precisión y ROC-AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suponiendo que la columna 'status_group' es la etiqueta a predecir\n",
    "X = df.drop('status_group', axis=1)\n",
    "y = df['status_group']\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "file_path = 'Reto_agua_final.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=2000),  # Aumentar el número de iteraciones\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'XGBoost': xgb.XGBClassifier(eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Entrenar y evaluar cada modelo\n",
    "for name, model in models.items():\n",
    "    if name == 'Logistic Regression':\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    results[name] = {\n",
    "        'Train Accuracy': train_accuracy,\n",
    "        'Test Accuracy': test_accuracy\n",
    "    }\n",
    "\n",
    "# Mostrar los resultados\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elección del Mejor Modelo\n",
    "Basado en las métricas proporcionadas, el modelo de XGBoost muestra un rendimiento excelente con una buena precisión, recall y ROC-AUC, y no presenta un sobreajuste tan marcado como el Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aca se evalua el df completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "file_path = 'Reto_agua_final.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    if model_name == 'Logistic Regression':\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    print(f\"Evaluating {model_name}\")\n",
    "    print(\"Training Classification Report:\")\n",
    "    print(classification_report(y_train, y_pred_train))\n",
    "    \n",
    "    print(\"Testing Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "    \n",
    "    \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_probs = model.predict_proba(X_test)[:, 1]\n",
    "    else: \n",
    "        y_probs = model.decision_function(X_test)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_probs, pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f\"ROC-AUC Score: {roc_auc}\")\n",
    "    \n",
    "for name, model in models.items():\n",
    "    evaluate_model(model, X_train, y_train, X_test, y_test, name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Ejercicio 3 \n",
    "\n",
    "Seleccionad las 21 variables que más influyen en la predicción y entrenad de nuevo el \n",
    "modelo. ¿Mejora? \n",
    "\n",
    "Usadlas para sacar los scoring ['accuracy', 'precision', 'recall'] del conjunto de train: \n",
    "• ¿Interpreta accuracy? \n",
    "• ¿Interpreta precision? \n",
    "• ¿Interpreta recall? \n",
    "• ¿Predice mejor los positivos o los negativos? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacamos las 21 las 21 variables que más influyen en la predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'Reto_agua_final.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Calcular la correlación de cada característica con la variable objetivo 'status_group'\n",
    "correlation_matrix = df.corr()\n",
    "correlation_with_target = correlation_matrix['status_group'].abs()\n",
    "\n",
    "# Seleccionar las 21 características con la mayor correlación absoluta con 'status_group'\n",
    "top_21_features = correlation_with_target.sort_values(ascending=False).head(22).index.tolist()\n",
    "top_21_features.remove('status_group')  # Remover 'status_group' de la lista\n",
    "\n",
    "print(\"Las 21 variables que mejor correlacionan con 'status_group' son:\")\n",
    "print(top_21_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Volvemos a correr los modelos pero ahora con las 21 variables seleccionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "selected_columns = ['construction_year', 'quantity_group', 'payment_type', 'waterpoint_type_group', 'funder', \n",
    "                    'gps_height', 'scheme_management', 'extraction_type', 'water_quality_2', 'public_meeting', \n",
    "                    'region', 'permit', 'latitude', 'source_class', 'amount_tsh', 'basin', 'population', 'wpt_name', \n",
    "                    'management_group', 'installer', 'longitude']\n",
    "\n",
    "# Filtrar el DataFrame original para incluir solo las columnas seleccionadas\n",
    "X = df[selected_columns]\n",
    "y = df['status_group']\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test, model_name):\n",
    "    if model_name == 'Logistic Regression':\n",
    "        y_pred_train = model.predict(X_train_scaled)\n",
    "        y_pred_test = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "    \n",
    "    print(f\"Evaluating {model_name}\")\n",
    "    print(\"Training Classification Report:\")\n",
    "    print(classification_report(y_train, y_pred_train))\n",
    "    \n",
    "    print(\"Testing Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "    \n",
    "    \n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_probs = model.predict_proba(X_test)[:, 1]\n",
    "    else: \n",
    "        y_probs = model.decision_function(X_test)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_probs, pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f\"ROC-AUC Score: {roc_auc}\")\n",
    "    \n",
    "for name, model in models.items():\n",
    "    evaluate_model(model, X_train, y_train, X_test, y_test, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a ['accuracy', 'precision', 'recall']  \n",
    "\n",
    "• ¿Interpreta accuracy? \n",
    "• ¿Interpreta precision? \n",
    "• ¿Interpreta recall? \n",
    "• ¿Predice mejor los positivos o los negativos?\n",
    "\n",
    "Interpreta accuracy:\n",
    "\n",
    "Logistic Regression: Accuracy es moderada (0.75), indicando que el modelo predice correctamente el 75% de las veces.\n",
    "\n",
    "K-Nearest Neighbors: Accuracy es alta en el entrenamiento (0.87) pero baja en la prueba (0.80), sugiriendo posible sobreajuste.\n",
    "\n",
    "Random Forest: Accuracy es perfecta en el entrenamiento (1.00) y alta en la prueba (0.91), indicando sobreajuste.\n",
    "\n",
    "XGBoost: Accuracy es alta en ambos conjuntos (0.93 en entrenamiento y 0.90 en prueba), mostrando buen equilibrio y generalización.\n",
    "\n",
    "Interpreta Precision:\n",
    "\n",
    "\n",
    "Logistic Regression: Precision es moderada, sugiriendo que una proporción significativa de las predicciones positivas no son correctas.\n",
    "\n",
    "K-Nearest Neighbors: Precision es alta, especialmente para la clase 0 en el conjunto de entrenamiento.\n",
    "\n",
    "Random Forest: Precision es perfecta en el entrenamiento, indicando sobreajuste, pero alta en la prueba.\n",
    "\n",
    "XGBoost: Precision es alta y equilibrada en ambas clases y en ambos conjuntos, indicando buen rendimiento.\n",
    "\n",
    "Interpreta Recall:\n",
    "\n",
    "Logistic Regression: Recall es moderada, especialmente baja para la clase 1.\n",
    "\n",
    "K-Nearest Neighbors: Recall es alta en el conjunto de entrenamiento, pero disminuye en el conjunto de prueba, sugiriendo sobreajuste.\n",
    "\n",
    "Random Forest: Recall es perfecta en el entrenamiento, indicando sobreajuste, pero alta en la prueba.\n",
    "\n",
    "XGBoost: Recall es alta y equilibrada en ambas clases y en ambos conjuntos, indicando buen rendimiento.\n",
    "\n",
    "¿Predice mejor los positivos o los negativos?:\n",
    "\n",
    "Logistic Regression: Predice mejor los negativos (clase 0), dado que tanto la precisión como el recall son más altos para la clase 0 en comparación con la clase 1.\n",
    "\n",
    "K-Nearest Neighbors: Predice mejor los negativos (clase 0) tanto en el entrenamiento como en la prueba, aunque hay una disminución en el rendimiento para ambas clases en el conjunto de prueba.\n",
    "\n",
    "Random Forest: Predice bien ambas clases en el conjunto de prueba, aunque hay una ligera ventaja para los negativos (clase 0).\n",
    "\n",
    "XGBoost: Predice bien ambas clases, con una ligera ventaja para los negativos (clase 0) en términos de recall en el conjunto de prueba.\n",
    "\n",
    "Comparación con Resultados Anteriores\n",
    "\n",
    "Logistic Regression: No hay mejora significativa en los resultados.\n",
    "\n",
    "K-Nearest Neighbors: Similar rendimiento, con ligero sobreajuste.\n",
    "\n",
    "Random Forest: Similar rendimiento, sigue mostrando sobreajuste.\n",
    "\n",
    "XGBoost: Muestra una ligera mejora en la generalización y sigue siendo el mejor modelo en términos de equilibrio entre precisión y recall.\n",
    "\n",
    "Conclusión\n",
    "\n",
    "XGBoost sigue siendo el mejor modelo en términos de rendimiento general y balance entre las métricas.\n",
    "\n",
    "Random Forest muestra sobreajuste significativo.\n",
    "\n",
    "K-Nearest Neighbors muestra un ligero sobreajuste.\n",
    "\n",
    "Logistic Regression tiene un rendimiento moderado y consistente, pero no es el mejor modelo para este problema.\n",
    "\n",
    "El uso de las 21 variables más importantes parece mantener o mejorar ligeramente el rendimiento de XGBoost, indicando que estas variables son relevantes y suficientes para una buena predicción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. Ejercicio 4 \n",
    "\n",
    "Validad la correlación con uno o más gráficos con las columnas ['amount_tsh', 'funder', \n",
    "'gps_height', 'installer', 'longitude', 'latitude', 'num_private', 'basin','status_group']. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "file_path = 'Reto_agua_final.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# Gráfico de dispersión para 'amount_tsh' vs 'gps_height'\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data['amount_tsh'], data['gps_height'], alpha=0.5)\n",
    "plt.title('Scatter Plot: amount_tsh vs gps_height')\n",
    "plt.xlabel('amount_tsh')\n",
    "plt.ylabel('gps_height')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Gráfico de dispersión para 'longitude' vs 'latitude'\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data['longitude'], data['latitude'], alpha=0.5)\n",
    "plt.title('Scatter Plot: longitude vs latitude')\n",
    "plt.xlabel('longitude')\n",
    "plt.ylabel('latitude')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Diagrama de cajas para 'amount_tsh' vs 'status_group'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='status_group', y='amount_tsh', data=data)\n",
    "plt.title('Box Plot: amount_tsh vs status_group')\n",
    "plt.xlabel('status_group')\n",
    "plt.ylabel('amount_tsh')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Diagrama de cajas para 'gps_height' vs 'status_group'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='status_group', y='gps_height', data=data)\n",
    "plt.title('Box Plot: gps_height vs status_group')\n",
    "plt.xlabel('status_group')\n",
    "plt.ylabel('gps_height')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Diagrama de cajas para 'population' vs 'status_group'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='status_group', y='population', data=data)\n",
    "plt.title('Box Plot: population vs status_group')\n",
    "plt.xlabel('status_group')\n",
    "plt.ylabel('population')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Mapa de calor para las correlaciones entre variables numéricas\n",
    "numerical_columns = ['amount_tsh', 'gps_height', 'longitude', 'latitude', 'population']\n",
    "correlation_matrix = data[numerical_columns].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Heatmap: Correlation Matrix')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después, haced un gráfico, el que consideréis adecuado, para detectar outliers en \n",
    "population y gps_height ¿alguno tiene outliers?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "file_path = 'Reto_agua_final.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Diagrama de cajas para 'population'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=data['population'])\n",
    "plt.title('Box Plot: population')\n",
    "plt.xlabel('population')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Diagrama de cajas para 'gps_height'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=data['gps_height'])\n",
    "plt.title('Box Plot: gps_height')\n",
    "plt.xlabel('gps_height')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sí, el gráfico de caja para la columna population muestra claramente la presencia de outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De ser así, eliminadlos con el método de \n",
    "Inter cuartil con la columna o columnas con datos atípicos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "file_path = 'Reto_agua_final.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Definir una función para eliminar outliers usando el método IQR para una columna específica\n",
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# Eliminar outliers en la columna 'population'\n",
    "df = remove_outliers_iqr(data, 'population')\n",
    "\n",
    "# Diagrama de cajas para 'population' después de eliminar outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df['population'])\n",
    "plt.title('Box Plot: population (sin outliers)')\n",
    "plt.xlabel('population')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gráfico generado muestra que aún existen algunos valores considerados como outliers en la columna population, sin embargo son valores muy proximos al limite superior y estan concentrados entre los 500 y 650 pobladores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " ¿El modelo ha mejorado? \n",
    "Recordad que hay que volver a sacar los valores x e y (test y train). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "\n",
    "X = data.drop(columns=['status_group'])\n",
    "y = data['status_group']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# modelo XGBClassifier\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# prueba\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred, average='weighted')\n",
    "test_recall = recall_score(y_test, y_test_pred, average='weighted')\n",
    "test_classification_rep = classification_report(y_test, y_test_pred)\n",
    "\n",
    "# entrenamiento\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_precision = precision_score(y_train, y_train_pred, average='weighted')\n",
    "train_recall = recall_score(y_train, y_train_pred, average='weighted')\n",
    "train_classification_rep = classification_report(y_train, y_train_pred)\n",
    "\n",
    "print(\"Testing Metrics:\")\n",
    "print(f'Accuracy: {test_accuracy}')\n",
    "print(f'Precision: {test_precision}')\n",
    "print(f'Recall: {test_recall}')\n",
    "print('Classification Report:')\n",
    "print(test_classification_rep)\n",
    "\n",
    "print(\"\\nTraining Metrics:\")\n",
    "print(f'Accuracy: {train_accuracy}')\n",
    "print(f'Precision: {train_precision}')\n",
    "print(f'Recall: {train_recall}')\n",
    "print('Classification Report:')\n",
    "print(train_classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  ¿El modelo ha mejorado?  \n",
    "\n",
    "*Entrenamiento*: Las métricas de entrenamiento son muy similares entre las nuevas y las anteriores. No hay una mejora significativa.\n",
    "\n",
    "*Prueba:* Las métricas de prueba también son muy similares entre las nuevas y las anteriores.\n",
    "En general, no hay una mejora significativa entre las nuevas métricas y las anteriores. Ambas versiones del modelo muestran un rendimiento similar tanto en los conjuntos de entrenamiento como en los de prueba. Sin embargo, el nuevo modelo muestra un rendimiento ligeramente inferior en términos de precision y recall en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afinamos el modelo usando GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afinando el modelo\n",
    "\n",
    "El modelo XGBoost afinado muestra un excelente rendimiento tanto en el conjunto de entrenamiento como en el de prueba.\n",
    "El modelo no parece tener problemas significativos de sobreajuste o infraajuste.\n",
    "El alto ROC-AUC Score (0.9645) indica una excelente capacidad de discriminación entre las clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(eval_metric='mlogloss')\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_xgb_model = grid_search.best_estimator_\n",
    "evaluate_model(best_xgb_model, X_train, y_train, X_test, y_test, \"XGBoost (Tuned)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusión sobre el ajuste de Hyperparametros\n",
    "\n",
    "Entrenamiento:\n",
    "\n",
    "Las métricas de entrenamiento han mejorado significativamente con el ajuste de los hiperparámetros. La precisión, el recall y el f1-score han aumentado a 0.96, lo que indica que el modelo está ajustándose mejor a los datos de entrenamiento.\n",
    "\n",
    "Prueba:\n",
    "\n",
    "Las métricas de prueba se mantienen aproximadamente igual, con una precisión, recall y f1-score de 0.90. Sin embargo, el ROC-AUC Score ha mejorado ligeramente de 0.9627 a 0.9645.\n",
    "El ajuste de hiperparámetros ha mejorado el rendimiento del modelo en los datos de entrenamiento, lo que sugiere que el modelo está mejor ajustado. Aunque las métricas en el conjunto de prueba no han mejorado significativamente, la ligera mejora en el ROC-AUC Score indica un mejor rendimiento general del modelo ajustado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
